{
    "generate_text": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "outline",
            "input": "",         
            "output": " In  this  thesis,  we  will  begin  with  a  general  form  of  the  interactive  model  using  partiallyobservable  discrete-time  stochastic  hybrid  systems  and  its  discrete  version,  POMDP  forhuman-in-the-loop  systems  in  Chapter  2.   We  will  further  advance  to  the  computationalchallenge of its optimal control problem in Chapter 3, and show a significant improvementin  the  computational  time.   Applications  to  a  driver  assistance  system  shows  the  efficacyof  our  proposed  method.   In  Chapter  4,  we  incorporate  the  safety  constraint  by  a  novelmodel predictive control based planning framework, which enables the autonomous systemto explore the hidden human intent and achieve its goal with hard safety constraints.  Finally,we draw conclusion and present some future directions in Chapter 5.  The contribution ofeach chapter is as follows.Chapter 2Traditional human-assistance features such as warning systems in aircrafts and automaticbraking systems in automobiles only monitor the states of the machine in order to preventhuman errors and enhance safety.  We believe that next generation systems should be ableto monitor both the human and the machine and give an appropriate feedback to them.  Inthis chapter, we present a unified modeling framework to manage the feedback between thehuman and the machine.  Beginning with the general form of the interactive model usingpartially observable discrete-time stochastic hybrid systems, and we show how its discreteform partially observable Markov decision process can be used as a unified framework forthe three main components in a human-in-the-loop control systemâ€”the human model, themachine dynamic model and the observation model.  Our simulations show the benefits ofthis framework.Chapter 3We propose an efficient algorithm to find an optimal control policy in a discrete-time hiddenmode stochastic hybrid system, which is a special case of partially observable discrete-timestochastic hybrid systems in which only the discrete state is hidden and is used to modelthe hidden human intent.  The optimal control problem of hidden mode stochastic hybridsystem is known to have high computational complexity due to the continuous state space.We tackle this computational challenge by computing the lower bound of the value function,approximating  the  optimal  expected  reward  by  local  quadratic  functions,  and  using  thepoint-based value iteration technique.  A significant improvement in the computational timeis shown.  Moreover,  a driver assistance application demonstrates the enhancement of thequality of decision-making via our formulation. Chapter 4Finally, we incorporate hard system and safety constraints by a novel model predictive con-trol based framework.  Further approximations are proposed to deal with the computationalcomplexity.   We  show  that  in  addition  to  the  task  completion,  our  planning  method  alsoencourages exploration of the human intent and maintains safety.  We show that the actionof an autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.  Applica-tions on two autonomous driving scenarios show that our method results in a more efficientand effective control policy."    
        }
        
    ],
    "generate_abstract": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "abstract",
            "input": "",         
            "output": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency."    
        }
        
    ],
    "generate_intro": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "introduction",
            "input": "",         
            "output": "Autonomous  systems  or  robots  have  been  used  increasingly  in  todayâ€™s  society,  from  tra-ditional robotic manipulators in factories,  to medical robots in hospitals and autonomousvehicles  on  our  roads.   While  traditionally  robots  just  remain  in  restricted  environmentssuch  as  factories  to  do  repetitive  jobs,  they  start  to  appear  in  more  complex,  open  andless  structured  environments  that  involve  humans.   They  have  to  collaborate  or  interactwith humans in order to complete their tasks, such as autonomous vehicles interacting withother  human  drivers  or  pedestrians,  surgical  robots  collaborating  with  doctors,  or  driverassistance systems helping human drivers.  Because of this, the interactive ability becomesessential to many autonomous systems, especially systems requiring continuous interactionswith humans.  This leads to an increasing research and studies in the field of human-robotinteraction.   The  goal  is  to  study  the  fundamental  principles  of  interactions  and  developalgorithms for interactive behaviors to help the robot or human-robot as a whole achievecertain tasks safely and efficiently.Depending on different levels of autonomy [Par+00], interactions between autonomoussystems  and  humans  can  be  divided  into  passive  and  active  interactions.   As  shown  inFigure 1.1a, some autonomous systems such as manual control systems or driver assistancesystems only perform a passive interaction with the human, in which the autonomous systemwill estimate the human state and receive the human action, and then make decision basedon  them.   In  such  systems,  the  human  behavior  model  is  not  embedded  in  the  decision-making loop, so that the autonomous system will ignore how the change of the system statewill affect the human state and her action.A more desirable system will be able to take the effect of the autonomous system statesand  actions  on  the  human  into  account  in  its  decision-making  process,  as  shown  in  Fig-ure 1.1b.  In this active interactive model, the autonomous system will still infer the humanintent and state, and will further consider how its action affects the human state and actionas well.  The arrow of the system action in Figure 1.1b does not necessarily mean there isdirect action that affects the human.  It means the autonomous system is now aware of thesystem actions will influence the human.  Therefore, the human is now considered as a partof the decision-making loop and we call the whole system ahuman-in-the-loopsystem. 1.1    Human-In-The-Loop SystemsHaving human in the control loop is more similar to human interactions, where each personwill predict the otherâ€™s intent and actions and how her actions will affect the otherâ€™s intentand actions.  For example, when a driver tries to merge into the other lane, the driver willtry to predict whether the driver in the other lane will yield to her by observing the behaviorof the other driver.  Based on her prediction, she may decide whether to cut in front of theother driver given the knowledge that if she really cut, the other driver will be likely to slowdown to prevent collision.  She will decide when to merge according to her confidence on herprediction, her internal preference on risk and the knowledge of how her action will affectthe other person.The above example enlightens us about some essential components of a human-in-the-loop system.â€¢Human intent and internal state prediction - the autonomous system needs to predictthe human intent and state according to observed behaviors from its sensors.  Thereare  various  cues  we  can  use  for  inferring  the  human  intent,  such  as  facial  expres-sion [Bet+00], gesture [Dru+04], speech [LN05] or motion [Mik+04].  If the observedcue does not directly represent the human intent, the autonomous system will need toinfer it.  Some popular techniques include hidden Markov model[Lef+16] and Bayesianinference [Bak+09].â€¢Human reactive model - based on the human intent and the state or action from theautonomous system, the human will response to the autonomous system accordingly.If we have a model of what the human will react,  the autonomous system can plana better sequence of decisions/actions to complete its task.  However,  obtaining thisreactive model is difficult because it is hard to capture all the factors that affect humandecisions in general.  We have to make assumption to limit the influential factors inthe  model.   To  learn  the  model,  techniques  such  as  expectation-maximization  algo-rithm [Lam+15][Lef+16] and inverse reinforcement learning [Sad+16b] can be used.Objective function - the objective function represents the purpose of the autonomoussystem,  which could be a cost function to be minimized or a reward function to bemaximized.  In some case, we know what states or control inputs are good and whatare bad and thus can explicitly specify the objective function.  In some cases, however,the objective function is difficult to specify manually, in which inverse reinforcementlearning  [NR+00]  is  usually  used  to  learn  the  objective  function  by  observing  howhumans will do to complete the task.â€¢Integrated framework - a planning framework for the autonomous system to make op-timal sequence of decisions during the interaction.  This should enable the autonomoussystems to leverage the above components to optimize its objective function and main-tain safe.We will see that in this thesis, with elaborate design of these components, the autonomoussystem are able to actively explore,  estimate or even control the human state in order tocomplete a specific task efficiently and safely.Although having human in the control loop has its advantage, there are challenges whendeploying it.  The first comes from the uncertainty of the human.  Human intent and behaviorare subject to complex physiological, psychological and environmental factors.  It is unclearwhat  kinds  of  parametric  or  non-parametric  models  are  suitable  to  capture  the  complextransition of the human state.  It is also hard to guarantee the initially learned model willremain accurate as the human behaviors may change over time by some unexpected externalfactors.  Moreover, human-in-the-loop systems lack a unified decision-making framework tomanage  different  components.   The  framework  should  be  able  to  handle  the  probabilisticproperties of human-in-the-loop systems because of the uncertainty of the human intent orthe human physiological state.  Second, it should be a sequential process that can take careof  the  long-term  planning  of  the  whole  system,  and  lastly,  it  should  be  robust  to  certainuncertainty.  In this thesis, we aim to tackle the challenges by employing a POMDP-basedand a MPC-based sequential decision making frameworks. We will show how they are capableof integrating the human model, the machine model and their interaction in a probabilisticframework for planning safer and more efficient decisions.1.2    Sequential Decision-MakingOne essential element of the computational framework in human-in-the-loop systems is theability  to  make  good  sequential  decisions  as  the  autonomous  system  requires  continuousinteraction with humans.  In this thesis, the following models and their variations are studiedand used as fundamental frameworks for human-in-the-loop systems modeling.Markov decision process (MDP) and partially observable Markov decisionprocess (POMDP)Markov decision process is a discrete time framework modeling the interaction between anagent and an environment.  Here the environment represents all our interested states.  Theagent is the only ego system that makes decision and interacts with the environment.  Forexample,  an  AI  system  that  plays  a  video  game  can  be  the  agent  while  the  game  is  theenvironment, or a driver assistance system can be the agent while the vehicle with a drivercan be the environment.  The Markov assumption made in MDPs is that the change of thestates only depends on the states in previous time step and the agentâ€™s action applying to theenvironment.  Instead of a deterministic state transition, the transition could be probabilisticin MDP, which allows us to model the randomness and the uncertainty of the environment.The goal of a Markov decision process is to find a control policy that decides the optimalaction the agent can take in order to optimize an expected objective function of the systemtrajectory.  MDPs allow us to consider the long-term effect of the system via the objectivefunction and the system dynamics.  Depending on whether we know the transition model inadvance, the techniques of finding the optimal policy can be divided into model-based meth-ods such as value iteration or policy iteration, and model-free methods such as reinforcementlearning [SB98].POMDP  is  similar  to  MDP  except  that  the  state  of  the  environment  cannot  be  fullyobserved.   Instead,  its  observation  is  drawn  from  a  probabilistic  distribution  conditioningon  the  underlying  hidden  state.   Since  the  true  state  is  hidden,  we  can  only  maintain  aprobability distribution over the possible hidden states.  The goal is to solve a control policythat  optimize  the  expected  objective  function  over  the  trajectory  too.   Since  the  state  isnot fully observed, the optimal control policy will take the probability distribution over thehidden states as an input and output an optimal action.  POMDP allows us to model a morerealistic interaction in a human-in-the-loop system because the autonomous system is notable to observe the intent of the human during the interaction, and human behaviors havecertain amount of randomness.  We will discuss it more in detail in Chapter 2,MDPs and POMDPs have been extensively studied in academic research and real-worlddecision making processes such as finding optimal strategy in games [Tes95] and spoken dialogsystems [WY07], etc.  However, the computational challenges arise when the system becomehigh  dimensional  or  continuous,  especially  for  POMDP,  in  which  the  partially  observablenature creates more complexity.  We will focus on how further approximations or heuristicscan mediate this computational challenge in Chapter 3.Model predictive control (MPC)Model predictive control solves a finite time optimal control problem at each time steptthatoptimizes the objective function over the future trajectories subject to the system dynamicsand system constraints,minimize{xt+1:t+N},{ut:t+Nâˆ’1}t+Nâˆ’1âˆ‘Ï„=tJ(xÏ„,uÏ„)(1.2.1a)subject toxÏ„+1=f(xÏ„,uÏ„)âˆ€Ï„= 1,Â·Â·Â·,t+Nâˆ’1(1.2.1b)C(xÏ„,uÏ„)â‰¤0âˆ€Ï„= 1,Â·Â·Â·,t+Nâˆ’1(1.2.1c)wherexÏ„anduÏ„are the (predicted) states and control inputs of the system at timeÏ„.  Func-tionJ,fandCare the cost function, the system dynamics and the constraint function.Nis the horizon we considered.  The above open-loop constrained optimal control problem issolved online at every time step, but the real system will only execute the control input ofthe first time step.  The real system state evolves for one time step and then the computa-tion is repeated starting from the new current state with a new horizon decreased by one.Model predictive control has demonstrated good results for control problems involving largenumbers of states and control inputs [ML99].  By solving the optimization problem 1.2.1,thehardconstraints on states and control inputs can be rigorously enforced as well, whichis a main advantage of MPC over MDP, in which we can only embedded the constraints intothe objective function.The  system  dynamics  may  be  subject  to  noise,  i.e.,xÏ„+1=f(xÏ„,uÏ„,wÏ„),  wherewÏ„represents the noise in the system.wÏ„is assumed to be bounded and deterministic in therobust model predictive control framework [RH06][Lan+04].  If the nature of the uncertaintywÏ„is probabilistic, we can explicitly account for the probabilistic uncertainties by stochasticmodel predictive control framework,minimize{xt+1:t+N},{ut:t+Nâˆ’1}t+Nâˆ’1âˆ‘Ï„=tE[J(xÏ„,uÏ„)](1.2.2a)subject toxÏ„+1âˆ¼f(xâ€²|xÏ„,uÏ„)âˆ€Ï„= 1,Â·Â·Â·,t+Nâˆ’1(1.2.2b)Pr[C(xÏ„,uÏ„)â‰¤0]â‰¥pâˆ€Ï„= 1,Â·Â·Â·,t+Nâˆ’1(1.2.2c)wherefis now the probability density function describing the characteristic of the proba-bilistic transition.  The constraints becomechance constraints, which require the constraintson states and control inputs being satisfied with at least a specified probability levelp.The challenge of MPC that hinders us to use it in every sequential decision making prob-lem is that it requires solving an optimization problem at each time step in real time.  Muchacademic research has been done to develop fast algorithm to deal with it [KB12][T+03].However, there is no universal algorithm that can apply to every MPC problem, so accordingto different applications, different techniques are used in order to accelerate the computa-tion.  In Chapter 4, other than proposing our human-in-the-loop decision-making frameworkvia  MPC,  we  also  develop  our  approximations  and  heuristics  to  tackle  the  computationchallenge."
        }
 
    ],
    "generate_survey": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "survey",
            "input": "",         
            "output": ""     
        }
       
    ],
    "generate_methodology": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "methodology",
            "input": "",         
            "output": ""
        }
        
    ],
    "generate_experiment": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "experiment",
            "input": "",         
            "output": ""  
        }
        
    ],
    "generate_discussion": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "discussion",
            "input": "",         
            "output": ""
        }
    ],
    "generate_conclusion": [
        {
            "title": "Improving Sequential Decision Making in Human-In-The-Loop Systems",
            "tl;dr": "",         
            "abstract": "Interactions between humans and autonomous systems are always necessary.  They couldbe very simple interactions such as a person pushing a button to trigger a specific function,or more complicated interactions such as an autonomous vehicle interacting with other hu-man drivers.  Therefore, a safe and efficient interaction is crucial for advancing autonomoussystems, especially those requiring persistent interactions with humans.One common type of such systems is the human-assistance system such as warning sys-tems in the aircraft and automatic braking systems in automobile.  Traditionally, they onlymonitor the states of the machine to prevent human errors and enhance safety, but not takeinto account the state of the human in their decision-making processes, arguably the greatestvariability affecting the safety.  In light of the above drawbacks, we believe that more desir-able autonomous systems should take the human state into account in their decision-makingprocesses.  In other words,  other than the task completion,  the exploration,  estimation oreven control of the human state should be a part of the decision-making loop in suchhuman-in-the-loopsystems. Moreover, to estimate the state of the human, most autonomous systemsjust passively gain information from their sensors, while ignoring the fact that the action ofthe autonomous system can actually help understand and estimate the human state better,and a better understanding of the human state will better achieve its goal as well.In  this  thesis,  we  will  develop  frameworks  and  computational  tools  for  human-in-the-loop systems to achieve a safe and efficient interaction.  Beginning with a general form ofthe  interactive  model  using  a  partially  observable  discrete-time  stochastic  hybrid  system,we  describe  how  its  discrete  form,  partially  observable  Markov  decision  process,  can  beused to integrate the human model, the machine dynamical model and their interaction ina  probabilistic  framework.   We  will  further  advance  the  discrete  version  to  hidden  modestochastic hybrid systems that can consider continuous states with discrete hidden modesused  to  model  the  hidden  human  intents.   We  tackle  the  computational  challenge  of  theoptimal control problem in hidden mode stochastic hybrid systems and show a significantimprovement in the computational time.  A driver-assistance application shows the efficacyof  our  proposed  method.   Finally,  we  propose  to  incorporate  the  safety  constraint  by  a novel  model  predictive  control  based  framework,  which  will  encourage  the  exploration  ofthe hidden human intent as well as achieving its goal with hard safety constraints.  Takingthem together, these contributions advance the computational framework for next generationhuman-in-the-loop systems, which are capable to monitor both the human and the machinestates,activelyexplore the human intent, and give appropriate feedbacks to them in orderto enhance both safety and efficiency.",
            "keywords": "",   
            "section": "conclusion",
            "input": "",         
            "output": "This thesis contributes to the development of frameworks and computational tools for de-signing safe and efficient human-in-the-loop systems in which human intents are hidden.  APOMDP-based (Chapter 2 and 3) and a MPC-based (Chapter 4) sequential decision-makingframeworks are proposed to integrate the human model, the machine dynamical model andtheir interaction.  There are different venues for these two frameworks.  The POMDP-basedapproach is a model-based formulation for planning in multi-intent human-in-the-loop sys-tems whose optimal policy can be solved offline.  Although it takes more time to computethe control policy, once we solve the policy, running the policy can be very fast and done inreal time.  Therefore, it is suitable for non-safety-critical systems that require fast interactivebehavior.  On the other hand, the MPC-based approach requires a longer time horizon sinceit has to solve an optimization problem in real time, but its advantage is that it can incorpo-rate hard constraints so it guarantees the constraints will not be violated.  Our results showthat both approaches enable us to design autonomous systems that are aware of the effectof their actions on the human, resulting in a faster identification of human intents, a saferinteraction,  and a better balance among decisions that gather information,  decisions thatchange the human intent and decisions that complete the goal.Furthermore, the computational challenges are addressed and tackled in Chapter 3 and 4.We  utilize  quadratic  function  approximation,  lower  bound  update  and  point-based  valueiteration to make solving an optimal policy possible in the hidden mode stochastic hybridsystem,  which  results  in  a  significant  improvement  on  the  computational  time.   For  theMPC-based  method,  Gaussian  approximations,  covariance  updates  and  linear  constraintapproximations are used to accelerate the computation, making the intractable formulationbecome a tractable problem.Taking them together, our contributions provide a formalism for designing efficient andsafe human-in-the-loop systems."    
        }

    ]
    
} 